{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/meghanshu/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['/job:localhost/replica:0/task:0/device:GPU:0']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import pandas as pd\n",
    "from keras import backend as K\n",
    "K.tensorflow_backend._get_available_gpus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing import image,sequence\n",
    "from keras.applications import VGG16\n",
    "from keras.layers import Dense,Convolution2D,Embedding,Dropout,LSTM,TimeDistributed,Bidirectional,Activation,RepeatVector,Merge,Flatten\n",
    "from keras.optimizers import Adam, RMSprop,Nadam\n",
    "from keras.models import Sequential, Model\n",
    "import nltk\n",
    "import glob\n",
    "from PIL import Image\n",
    "%matplotlib inline\n",
    "import pickle\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/meghanshu/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:1264: calling reduce_prod (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "OOM when allocating tensor with shape[25088,4096] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[Node: fc1/random_uniform/RandomUniform = RandomUniform[T=DT_INT32, dtype=DT_FLOAT, seed=87654321, seed2=9983617, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](fc1/random_uniform/shape)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\nCaused by op 'fc1/random_uniform/RandomUniform', defined at:\n  File \"/home/meghanshu/anaconda3/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/home/meghanshu/anaconda3/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/meghanshu/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/home/meghanshu/anaconda3/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/home/meghanshu/anaconda3/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 477, in start\n    ioloop.IOLoop.instance().start()\n  File \"/home/meghanshu/anaconda3/lib/python3.6/site-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/home/meghanshu/anaconda3/lib/python3.6/site-packages/tornado/ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"/home/meghanshu/anaconda3/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/meghanshu/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/home/meghanshu/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/home/meghanshu/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/home/meghanshu/anaconda3/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/meghanshu/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/home/meghanshu/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 235, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/home/meghanshu/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/home/meghanshu/anaconda3/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/meghanshu/anaconda3/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/meghanshu/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2717, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/meghanshu/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2821, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/home/meghanshu/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2881, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-3-addb6c270b5f>\", line 1, in <module>\n    vgg = VGG16(weights='imagenet', include_top=True, input_shape=(224,224,3))\n  File \"/home/meghanshu/anaconda3/lib/python3.6/site-packages/keras/applications/vgg16.py\", line 145, in VGG16\n    x = Dense(4096, activation='relu', name='fc1')(x)\n  File \"/home/meghanshu/anaconda3/lib/python3.6/site-packages/keras/engine/topology.py\", line 576, in __call__\n    self.build(input_shapes[0])\n  File \"/home/meghanshu/anaconda3/lib/python3.6/site-packages/keras/layers/core.py\", line 830, in build\n    constraint=self.kernel_constraint)\n  File \"/home/meghanshu/anaconda3/lib/python3.6/site-packages/keras/legacy/interfaces.py\", line 87, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/meghanshu/anaconda3/lib/python3.6/site-packages/keras/engine/topology.py\", line 397, in add_weight\n    weight = K.variable(initializer(shape),\n  File \"/home/meghanshu/anaconda3/lib/python3.6/site-packages/keras/initializers.py\", line 212, in __call__\n    dtype=dtype, seed=self.seed)\n  File \"/home/meghanshu/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\", line 3637, in random_uniform\n    dtype=dtype, seed=seed)\n  File \"/home/meghanshu/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/random_ops.py\", line 242, in random_uniform\n    rnd = gen_random_ops.random_uniform(shape, dtype, seed=seed1, seed2=seed2)\n  File \"/home/meghanshu/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/gen_random_ops.py\", line 674, in random_uniform\n    name=name)\n  File \"/home/meghanshu/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/home/meghanshu/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3414, in create_op\n    op_def=op_def)\n  File \"/home/meghanshu/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1740, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[25088,4096] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[Node: fc1/random_uniform/RandomUniform = RandomUniform[T=DT_INT32, dtype=DT_FLOAT, seed=87654321, seed2=9983617, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](fc1/random_uniform/shape)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m/home/meghanshu/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1321\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1322\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1323\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/meghanshu/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1306\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1307\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/meghanshu/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1408\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1409\u001b[0;31m           run_metadata)\n\u001b[0m\u001b[1;32m   1410\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[25088,4096] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[Node: fc1/random_uniform/RandomUniform = RandomUniform[T=DT_INT32, dtype=DT_FLOAT, seed=87654321, seed2=9983617, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](fc1/random_uniform/shape)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-addb6c270b5f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mvgg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVGG16\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'imagenet'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minclude_top\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m224\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m224\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/meghanshu/anaconda3/lib/python3.6/site-packages/keras/applications/vgg16.py\u001b[0m in \u001b[0;36mVGG16\u001b[0;34m(include_top, weights, input_tensor, input_shape, pooling, classes)\u001b[0m\n\u001b[1;32m    173\u001b[0m                                     \u001b[0mcache_subdir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'models'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m                                     file_hash='6d6bbae143d832006294945121d1f1fc')\n\u001b[0;32m--> 175\u001b[0;31m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    176\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'theano'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m             \u001b[0mlayer_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_all_kernels_in_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/meghanshu/anaconda3/lib/python3.6/site-packages/keras/engine/topology.py\u001b[0m in \u001b[0;36mload_weights\u001b[0;34m(self, filepath, by_name)\u001b[0m\n\u001b[1;32m   2620\u001b[0m             \u001b[0mload_weights_from_hdf5_group_by_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2621\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2622\u001b[0;31m             \u001b[0mload_weights_from_hdf5_group\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2623\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2624\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'close'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/meghanshu/anaconda3/lib/python3.6/site-packages/keras/engine/topology.py\u001b[0m in \u001b[0;36mload_weights_from_hdf5_group\u001b[0;34m(f, layers)\u001b[0m\n\u001b[1;32m   3141\u001b[0m                              ' elements.')\n\u001b[1;32m   3142\u001b[0m         \u001b[0mweight_value_tuples\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msymbolic_weights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3143\u001b[0;31m     \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_set_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight_value_tuples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3145\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/meghanshu/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36mbatch_set_value\u001b[0;34m(tuples)\u001b[0m\n\u001b[1;32m   2250\u001b[0m             \u001b[0massign_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0massign_op\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2251\u001b[0m             \u001b[0mfeed_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0massign_placeholder\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2252\u001b[0;31m         \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0massign_ops\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2253\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2254\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/meghanshu/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36mget_session\u001b[0;34m()\u001b[0m\n\u001b[1;32m    187\u001b[0m                     \u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_keras_initialized\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0muninitialized_vars\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 189\u001b[0;31m                     \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvariables_initializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muninitialized_vars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    190\u001b[0m     \u001b[0;31m# hack for list_devices() function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m     \u001b[0;31m# list_devices() function is not available under tensorflow r1.3.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/meghanshu/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    898\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    899\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 900\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    901\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    902\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/meghanshu/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1133\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1135\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1136\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1137\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/meghanshu/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1314\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1315\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1316\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1317\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/meghanshu/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1333\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1334\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1335\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1336\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1337\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[25088,4096] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[Node: fc1/random_uniform/RandomUniform = RandomUniform[T=DT_INT32, dtype=DT_FLOAT, seed=87654321, seed2=9983617, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](fc1/random_uniform/shape)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\nCaused by op 'fc1/random_uniform/RandomUniform', defined at:\n  File \"/home/meghanshu/anaconda3/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/home/meghanshu/anaconda3/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/meghanshu/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/home/meghanshu/anaconda3/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/home/meghanshu/anaconda3/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 477, in start\n    ioloop.IOLoop.instance().start()\n  File \"/home/meghanshu/anaconda3/lib/python3.6/site-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/home/meghanshu/anaconda3/lib/python3.6/site-packages/tornado/ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"/home/meghanshu/anaconda3/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/meghanshu/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/home/meghanshu/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/home/meghanshu/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/home/meghanshu/anaconda3/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/meghanshu/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/home/meghanshu/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 235, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/home/meghanshu/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/home/meghanshu/anaconda3/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/meghanshu/anaconda3/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/meghanshu/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2717, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/meghanshu/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2821, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/home/meghanshu/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2881, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-3-addb6c270b5f>\", line 1, in <module>\n    vgg = VGG16(weights='imagenet', include_top=True, input_shape=(224,224,3))\n  File \"/home/meghanshu/anaconda3/lib/python3.6/site-packages/keras/applications/vgg16.py\", line 145, in VGG16\n    x = Dense(4096, activation='relu', name='fc1')(x)\n  File \"/home/meghanshu/anaconda3/lib/python3.6/site-packages/keras/engine/topology.py\", line 576, in __call__\n    self.build(input_shapes[0])\n  File \"/home/meghanshu/anaconda3/lib/python3.6/site-packages/keras/layers/core.py\", line 830, in build\n    constraint=self.kernel_constraint)\n  File \"/home/meghanshu/anaconda3/lib/python3.6/site-packages/keras/legacy/interfaces.py\", line 87, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/meghanshu/anaconda3/lib/python3.6/site-packages/keras/engine/topology.py\", line 397, in add_weight\n    weight = K.variable(initializer(shape),\n  File \"/home/meghanshu/anaconda3/lib/python3.6/site-packages/keras/initializers.py\", line 212, in __call__\n    dtype=dtype, seed=self.seed)\n  File \"/home/meghanshu/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\", line 3637, in random_uniform\n    dtype=dtype, seed=seed)\n  File \"/home/meghanshu/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/random_ops.py\", line 242, in random_uniform\n    rnd = gen_random_ops.random_uniform(shape, dtype, seed=seed1, seed2=seed2)\n  File \"/home/meghanshu/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/gen_random_ops.py\", line 674, in random_uniform\n    name=name)\n  File \"/home/meghanshu/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/home/meghanshu/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3414, in create_op\n    op_def=op_def)\n  File \"/home/meghanshu/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1740, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[25088,4096] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[Node: fc1/random_uniform/RandomUniform = RandomUniform[T=DT_INT32, dtype=DT_FLOAT, seed=87654321, seed2=9983617, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](fc1/random_uniform/shape)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n"
     ]
    }
   ],
   "source": [
    "vgg = VGG16(weights='imagenet', include_top=True, input_shape=(224,224,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vgg = Model(inputs=vgg.input, outputs=vgg.layers[-2].output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd_dataset_train= pd.read_csv(\"./flickr_8k_train_dataset.txt\", delimiter='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>captions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2513260012_03d33305cf.jpg</td>\n",
       "      <td>&lt;start&gt; A black dog is running after a white d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2513260012_03d33305cf.jpg</td>\n",
       "      <td>&lt;start&gt; Black dog chasing brown dog through sn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2513260012_03d33305cf.jpg</td>\n",
       "      <td>&lt;start&gt; Two dogs chase each other across the s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2513260012_03d33305cf.jpg</td>\n",
       "      <td>&lt;start&gt; Two dogs play together in the snow . &lt;...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2513260012_03d33305cf.jpg</td>\n",
       "      <td>&lt;start&gt; Two dogs running through a low lying b...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    image_id  \\\n",
       "0  2513260012_03d33305cf.jpg   \n",
       "1  2513260012_03d33305cf.jpg   \n",
       "2  2513260012_03d33305cf.jpg   \n",
       "3  2513260012_03d33305cf.jpg   \n",
       "4  2513260012_03d33305cf.jpg   \n",
       "\n",
       "                                            captions  \n",
       "0  <start> A black dog is running after a white d...  \n",
       "1  <start> Black dog chasing brown dog through sn...  \n",
       "2  <start> Two dogs chase each other across the s...  \n",
       "3  <start> Two dogs play together in the snow . <...  \n",
       "4  <start> Two dogs running through a low lying b...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd_dataset_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30000, 2)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd_dataset_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd_dataset_val= pd.read_csv(\"./flickr_8k_val_dataset.txt\", delimiter='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5000, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>captions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2090545563_a4e66ec76b.jpg</td>\n",
       "      <td>&lt;start&gt; the boy laying face down on a skateboa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2090545563_a4e66ec76b.jpg</td>\n",
       "      <td>&lt;start&gt; Two girls play on a skateboard in a co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2090545563_a4e66ec76b.jpg</td>\n",
       "      <td>&lt;start&gt; Two people play on a long skateboard ....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2090545563_a4e66ec76b.jpg</td>\n",
       "      <td>&lt;start&gt; Two small children in red shirts playi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2090545563_a4e66ec76b.jpg</td>\n",
       "      <td>&lt;start&gt; two young children on a skateboard goi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    image_id  \\\n",
       "0  2090545563_a4e66ec76b.jpg   \n",
       "1  2090545563_a4e66ec76b.jpg   \n",
       "2  2090545563_a4e66ec76b.jpg   \n",
       "3  2090545563_a4e66ec76b.jpg   \n",
       "4  2090545563_a4e66ec76b.jpg   \n",
       "\n",
       "                                            captions  \n",
       "0  <start> the boy laying face down on a skateboa...  \n",
       "1  <start> Two girls play on a skateboard in a co...  \n",
       "2  <start> Two people play on a long skateboard ....  \n",
       "3  <start> Two small children in red shirts playi...  \n",
       "4  <start> two young children on a skateboard goi...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(pd_dataset_val.shape)\n",
    "pd_dataset_val.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "caption_train_data=pd_dataset_train['captions']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "caption_train_data=caption_train_data.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30000"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(caption_train_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000\n"
     ]
    }
   ],
   "source": [
    "caption_val_data = pd_dataset_val['captions']\n",
    "caption_val_data = caption_val_data.tolist()\n",
    "print(len(caption_val_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words=10000,filters='', lower = 'True', split=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def caption_process(captions):\n",
    "    capt = np.array(captions).reshape(-1,5)\n",
    "    captp = capt.tolist()\n",
    "    return captp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2513260012_03d33305cf.jpg'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd_dataset_train['image_id'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<start> Black dog chasing brown dog through snow <end>'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd_dataset_train['captions'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<start> A black dog is running after a white dog in the snow . <end>',\n",
       " '<start> Black dog chasing brown dog through snow <end>',\n",
       " '<start> Two dogs chase each other across the snowy ground . <end>',\n",
       " '<start> Two dogs play together in the snow . <end>',\n",
       " '<start> Two dogs running through a low lying body of water . <end>']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(np.array(caption_train_data).reshape(-1,5)[0]).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "caption_train = caption_process(caption_train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "caption_val = caption_process(caption_val_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<start> A black dog is running after a white dog in the snow . <end>',\n",
       " '<start> Black dog chasing brown dog through snow <end>',\n",
       " '<start> Two dogs chase each other across the snowy ground . <end>',\n",
       " '<start> Two dogs play together in the snow . <end>',\n",
       " '<start> Two dogs running through a low lying body of water . <end>']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "caption_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "caption_train_list1 = list(itertools.chain.from_iterable(caption_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tokenizer.fit_on_texts(caption_train_list1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.preprocessing.text.Tokenizer at 0x7f460b2be438>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a': 1,\n",
       " '<start>': 2,\n",
       " '<end>': 3,\n",
       " '.': 4,\n",
       " 'in': 5,\n",
       " 'the': 6,\n",
       " 'on': 7,\n",
       " 'is': 8,\n",
       " 'and': 9,\n",
       " 'dog': 10,\n",
       " 'with': 11,\n",
       " 'man': 12,\n",
       " 'of': 13,\n",
       " 'two': 14,\n",
       " 'white': 15,\n",
       " 'black': 16,\n",
       " 'boy': 17,\n",
       " 'are': 18,\n",
       " 'woman': 19,\n",
       " 'girl': 20,\n",
       " ',': 21,\n",
       " 'to': 22,\n",
       " 'wearing': 23,\n",
       " 'at': 24,\n",
       " 'people': 25,\n",
       " 'water': 26,\n",
       " 'brown': 27,\n",
       " 'red': 28,\n",
       " 'young': 29,\n",
       " 'an': 30,\n",
       " 'his': 31,\n",
       " 'blue': 32,\n",
       " 'dogs': 33,\n",
       " 'running': 34,\n",
       " 'through': 35,\n",
       " 'playing': 36,\n",
       " 'while': 37,\n",
       " 'down': 38,\n",
       " 'shirt': 39,\n",
       " 'ball': 40,\n",
       " 'standing': 41,\n",
       " 'little': 42,\n",
       " 'grass': 43,\n",
       " 'snow': 44,\n",
       " 'child': 45,\n",
       " 'person': 46,\n",
       " 'jumping': 47,\n",
       " 'over': 48,\n",
       " 'three': 49,\n",
       " 'sitting': 50,\n",
       " 'front': 51,\n",
       " 'field': 52,\n",
       " 'holding': 53,\n",
       " 'small': 54,\n",
       " 'yellow': 55,\n",
       " 'green': 56,\n",
       " 'group': 57,\n",
       " 'by': 58,\n",
       " 'up': 59,\n",
       " 'large': 60,\n",
       " 'one': 61,\n",
       " 'walking': 62,\n",
       " 'her': 63,\n",
       " 'men': 64,\n",
       " 'children': 65,\n",
       " 'air': 66,\n",
       " 'into': 67,\n",
       " 'near': 68,\n",
       " 'mouth': 69,\n",
       " 'beach': 70,\n",
       " 'jumps': 71,\n",
       " 'runs': 72,\n",
       " 'another': 73,\n",
       " 'for': 74,\n",
       " 'street': 75,\n",
       " 'from': 76,\n",
       " 'its': 77,\n",
       " 'riding': 78,\n",
       " 'stands': 79,\n",
       " 'bike': 80,\n",
       " 'girls': 81,\n",
       " 'as': 82,\n",
       " 'outside': 83,\n",
       " 'play': 84,\n",
       " 'rock': 85,\n",
       " 'other': 86,\n",
       " 'looking': 87,\n",
       " 'orange': 88,\n",
       " 'out': 89,\n",
       " 'pink': 90,\n",
       " 'player': 91,\n",
       " 'next': 92,\n",
       " 'off': 93,\n",
       " 'camera': 94,\n",
       " 'pool': 95,\n",
       " 'their': 96,\n",
       " 'jacket': 97,\n",
       " 'hat': 98,\n",
       " 'behind': 99,\n",
       " 'around': 100,\n",
       " 'boys': 101,\n",
       " 'women': 102,\n",
       " 'toy': 103,\n",
       " 'soccer': 104,\n",
       " 'some': 105,\n",
       " 'wall': 106,\n",
       " 'sits': 107,\n",
       " 'background': 108,\n",
       " 'has': 109,\n",
       " 'dressed': 110,\n",
       " 'walks': 111,\n",
       " 'dirt': 112,\n",
       " 'plays': 113,\n",
       " 'stand': 114,\n",
       " 'mountain': 115,\n",
       " 'along': 116,\n",
       " 'top': 117,\n",
       " 'park': 118,\n",
       " 'football': 119,\n",
       " 'climbing': 120,\n",
       " 'looks': 121,\n",
       " 'building': 122,\n",
       " 'face': 123,\n",
       " 'stick': 124,\n",
       " 'four': 125,\n",
       " 'smiling': 126,\n",
       " 'grassy': 127,\n",
       " 'crowd': 128,\n",
       " 'across': 129,\n",
       " 'swimming': 130,\n",
       " 'carrying': 131,\n",
       " 'hill': 132,\n",
       " 'sand': 133,\n",
       " 'rides': 134,\n",
       " 'skateboard': 135,\n",
       " 'baby': 136,\n",
       " 'tree': 137,\n",
       " 'holds': 138,\n",
       " 'car': 139,\n",
       " 'each': 140,\n",
       " 'snowy': 141,\n",
       " 'tennis': 142,\n",
       " 'hair': 143,\n",
       " 'together': 144,\n",
       " 'ocean': 145,\n",
       " 'doing': 146,\n",
       " 'picture': 147,\n",
       " 'tan': 148,\n",
       " 'road': 149,\n",
       " 'him': 150,\n",
       " 'race': 151,\n",
       " 'jump': 152,\n",
       " 'area': 153,\n",
       " 'that': 154,\n",
       " 'bench': 155,\n",
       " 'bicycle': 156,\n",
       " 'it': 157,\n",
       " 'helmet': 158,\n",
       " \"'s\": 159,\n",
       " 'trick': 160,\n",
       " 'back': 161,\n",
       " 'sidewalk': 162,\n",
       " 'sit': 163,\n",
       " 'game': 164,\n",
       " 'shorts': 165,\n",
       " 'run': 166,\n",
       " 'ground': 167,\n",
       " 'catch': 168,\n",
       " 'fence': 169,\n",
       " 'basketball': 170,\n",
       " 'head': 171,\n",
       " 'swing': 172,\n",
       " 'dress': 173,\n",
       " 'kids': 174,\n",
       " 'hand': 175,\n",
       " 'something': 176,\n",
       " 'purple': 177,\n",
       " 'being': 178,\n",
       " 'frisbee': 179,\n",
       " 'skateboarder': 180,\n",
       " 'slide': 181,\n",
       " 'several': 182,\n",
       " 'lake': 183,\n",
       " 'wave': 184,\n",
       " 'there': 185,\n",
       " 'walk': 186,\n",
       " 'covered': 187,\n",
       " 'city': 188,\n",
       " 'ramp': 189,\n",
       " 'path': 190,\n",
       " 'side': 191,\n",
       " 'players': 192,\n",
       " 'posing': 193,\n",
       " 'track': 194,\n",
       " 'baseball': 195,\n",
       " 'big': 196,\n",
       " 'long': 197,\n",
       " 'high': 198,\n",
       " 'wooden': 199,\n",
       " 'coat': 200,\n",
       " 'pants': 201,\n",
       " 'watches': 202,\n",
       " 'boat': 203,\n",
       " 'arms': 204,\n",
       " 'ride': 205,\n",
       " 'trees': 206,\n",
       " 'them': 207,\n",
       " 'horse': 208,\n",
       " 'watching': 209,\n",
       " 'rocky': 210,\n",
       " 'couple': 211,\n",
       " 'motorcycle': 212,\n",
       " 'uniform': 213,\n",
       " 'rope': 214,\n",
       " 'rocks': 215,\n",
       " 'look': 216,\n",
       " 'under': 217,\n",
       " 'sunglasses': 218,\n",
       " 'grey': 219,\n",
       " 'suit': 220,\n",
       " 'hands': 221,\n",
       " 'racing': 222,\n",
       " 'dark': 223,\n",
       " 'watch': 224,\n",
       " 'sign': 225,\n",
       " 'jeans': 226,\n",
       " 'older': 227,\n",
       " 'towards': 228,\n",
       " 'beside': 229,\n",
       " 'table': 230,\n",
       " 'guy': 231,\n",
       " 'does': 232,\n",
       " 'pose': 233,\n",
       " 'lady': 234,\n",
       " 'snowboarder': 235,\n",
       " 'above': 236,\n",
       " 'who': 237,\n",
       " '\"': 238,\n",
       " 'ice': 239,\n",
       " 'river': 240,\n",
       " 'colorful': 241,\n",
       " 'yard': 242,\n",
       " 'striped': 243,\n",
       " 'cliff': 244,\n",
       " 'woods': 245,\n",
       " 'onto': 246,\n",
       " 'against': 247,\n",
       " 'taking': 248,\n",
       " 'open': 249,\n",
       " 'he': 250,\n",
       " 'midair': 251,\n",
       " 'asian': 252,\n",
       " 'blonde': 253,\n",
       " 'bird': 254,\n",
       " 'mountains': 255,\n",
       " 'leaps': 256,\n",
       " 'after': 257,\n",
       " 'chasing': 258,\n",
       " 'blond': 259,\n",
       " 'climbs': 260,\n",
       " 'hockey': 261,\n",
       " 'rider': 262,\n",
       " 'body': 263,\n",
       " 'laying': 264,\n",
       " 'inside': 265,\n",
       " 'cap': 266,\n",
       " 'smiles': 267,\n",
       " 'kid': 268,\n",
       " 'during': 269,\n",
       " 'glasses': 270,\n",
       " 'collar': 271,\n",
       " 'many': 272,\n",
       " 'old': 273,\n",
       " 'wet': 274,\n",
       " 'surrounded': 275,\n",
       " 'skier': 276,\n",
       " 'colored': 277,\n",
       " 'edge': 278,\n",
       " 'very': 279,\n",
       " 'fountain': 280,\n",
       " 'performing': 281,\n",
       " 'forest': 282,\n",
       " 'playground': 283,\n",
       " 'hanging': 284,\n",
       " 'five': 285,\n",
       " 'backpack': 286,\n",
       " 'others': 287,\n",
       " 'surfer': 288,\n",
       " 'takes': 289,\n",
       " 'outdoors': 290,\n",
       " 't-shirt': 291,\n",
       " 'whilst': 292,\n",
       " 'toddler': 293,\n",
       " 'night': 294,\n",
       " 'object': 295,\n",
       " 'biker': 296,\n",
       " 'brick': 297,\n",
       " 'trying': 298,\n",
       " 'team': 299,\n",
       " 'away': 300,\n",
       " 'guitar': 301,\n",
       " 'past': 302,\n",
       " 'talking': 303,\n",
       " 'making': 304,\n",
       " 'pole': 305,\n",
       " 'surfboard': 306,\n",
       " 'middle': 307,\n",
       " 'light': 308,\n",
       " 'arm': 309,\n",
       " 'gray': 310,\n",
       " 'shore': 311,\n",
       " 'this': 312,\n",
       " 'bed': 313,\n",
       " 'flying': 314,\n",
       " 'window': 315,\n",
       " 'haired': 316,\n",
       " 'eating': 317,\n",
       " 'carries': 318,\n",
       " 'someone': 319,\n",
       " 'going': 320,\n",
       " 'trail': 321,\n",
       " 'about': 322,\n",
       " 'toward': 323,\n",
       " 'tall': 324,\n",
       " 'flowers': 325,\n",
       " 'line': 326,\n",
       " 'dancing': 327,\n",
       " 'outfit': 328,\n",
       " 'clothes': 329,\n",
       " 'sky': 330,\n",
       " 'swinging': 331,\n",
       " 'leash': 332,\n",
       " 'course': 333,\n",
       " 'nearby': 334,\n",
       " 'bridge': 335,\n",
       " 'plastic': 336,\n",
       " 'stone': 337,\n",
       " 'steps': 338,\n",
       " 'bag': 339,\n",
       " 'poses': 340,\n",
       " 'leaping': 341,\n",
       " 'floor': 342,\n",
       " 'sliding': 343,\n",
       " 'shallow': 344,\n",
       " 'between': 345,\n",
       " 'catches': 346,\n",
       " 'ready': 347,\n",
       " 'legs': 348,\n",
       " 'waves': 349,\n",
       " 'fighting': 350,\n",
       " 'shirts': 351,\n",
       " 'gear': 352,\n",
       " 'splashing': 353,\n",
       " 'bright': 354,\n",
       " 'all': 355,\n",
       " 'house': 356,\n",
       " 'climber': 357,\n",
       " 'room': 358,\n",
       " 'skateboarding': 359,\n",
       " 'costume': 360,\n",
       " 'tongue': 361,\n",
       " 'chair': 362,\n",
       " 'day': 363,\n",
       " 'board': 364,\n",
       " 'obstacle': 365,\n",
       " 'sandy': 366,\n",
       " 'swings': 367,\n",
       " 'lawn': 368,\n",
       " 'clothing': 369,\n",
       " 'leaves': 370,\n",
       " 'they': 371,\n",
       " 'mud': 372,\n",
       " 'metal': 373,\n",
       " 'golden': 374,\n",
       " 'get': 375,\n",
       " 'railing': 376,\n",
       " 'jersey': 377,\n",
       " 'outdoor': 378,\n",
       " 'winter': 379,\n",
       " 'wears': 380,\n",
       " 'smile': 381,\n",
       " 'male': 382,\n",
       " 'store': 383,\n",
       " 'adults': 384,\n",
       " 'getting': 385,\n",
       " 'drink': 386,\n",
       " 'adult': 387,\n",
       " 'lot': 388,\n",
       " 'female': 389,\n",
       " 'sun': 390,\n",
       " 'drinking': 391,\n",
       " 'waiting': 392,\n",
       " 'gets': 393,\n",
       " 'bar': 394,\n",
       " 'concrete': 395,\n",
       " 'sled': 396,\n",
       " 'catching': 397,\n",
       " 'set': 398,\n",
       " 'uniforms': 399,\n",
       " 'overlooking': 400,\n",
       " 'trampoline': 401,\n",
       " 'stairs': 402,\n",
       " 'skiing': 403,\n",
       " 'sweater': 404,\n",
       " 'rail': 405,\n",
       " 'bathing': 406,\n",
       " 'wooded': 407,\n",
       " 'makes': 408,\n",
       " 'leaning': 409,\n",
       " 'distance': 410,\n",
       " 'pulling': 411,\n",
       " 'horses': 412,\n",
       " 'train': 413,\n",
       " 'fire': 414,\n",
       " 'huge': 415,\n",
       " 'laughing': 416,\n",
       " 'swims': 417,\n",
       " 'number': 418,\n",
       " 'chases': 419,\n",
       " 'hats': 420,\n",
       " 'cellphone': 421,\n",
       " 'busy': 422,\n",
       " 'tricks': 423,\n",
       " 'fishing': 424,\n",
       " 'throwing': 425,\n",
       " 'eyes': 426,\n",
       " 'umbrella': 427,\n",
       " 'shirtless': 428,\n",
       " 'animal': 429,\n",
       " 'puppy': 430,\n",
       " 'flies': 431,\n",
       " 'tries': 432,\n",
       " 'hold': 433,\n",
       " 'performs': 434,\n",
       " 'swim': 435,\n",
       " 'nose': 436,\n",
       " 'vest': 437,\n",
       " 'puddle': 438,\n",
       " 'hurdle': 439,\n",
       " 'stream': 440,\n",
       " 'snowboard': 441,\n",
       " 'pond': 442,\n",
       " 'bubbles': 443,\n",
       " 'lying': 444,\n",
       " 'view': 445,\n",
       " 'elderly': 446,\n",
       " 'surfing': 447,\n",
       " 'life': 448,\n",
       " 'deep': 449,\n",
       " 'climb': 450,\n",
       " 'upside': 451,\n",
       " 'food': 452,\n",
       " 'ski': 453,\n",
       " 'muddy': 454,\n",
       " 'guys': 455,\n",
       " 'tank': 456,\n",
       " 'american': 457,\n",
       " 'trunks': 458,\n",
       " 'hiker': 459,\n",
       " 'or': 460,\n",
       " 'dry': 461,\n",
       " 'photo': 462,\n",
       " 'reading': 463,\n",
       " 'take': 464,\n",
       " 'no': 465,\n",
       " 'wetsuit': 466,\n",
       " 'tire': 467,\n",
       " 'truck': 468,\n",
       " 'left': 469,\n",
       " 'bags': 470,\n",
       " 'equipment': 471,\n",
       " 'slope': 472,\n",
       " 'both': 473,\n",
       " 'feet': 474,\n",
       " 'slides': 475,\n",
       " 'flag': 476,\n",
       " 'court': 477,\n",
       " 'bat': 478,\n",
       " 'right': 479,\n",
       " 'shoes': 480,\n",
       " 'surf': 481,\n",
       " 'flip': 482,\n",
       " 'like': 483,\n",
       " 'dresses': 484,\n",
       " 'she': 485,\n",
       " 'flags': 486,\n",
       " 'vehicle': 487,\n",
       " 'turn': 488,\n",
       " 'ledge': 489,\n",
       " 'coming': 490,\n",
       " 'harness': 491,\n",
       " 'couch': 492,\n",
       " 'shopping': 493,\n",
       " 'mask': 494,\n",
       " 'greyhound': 495,\n",
       " 'skirt': 496,\n",
       " 'book': 497,\n",
       " 'dock': 498,\n",
       " 'be': 499,\n",
       " 'falling': 500,\n",
       " 'bikes': 501,\n",
       " 'stunt': 502,\n",
       " 'structure': 503,\n",
       " 'waterfall': 504,\n",
       " 'raft': 505,\n",
       " 'subway': 506,\n",
       " 'lone': 507,\n",
       " 'cement': 508,\n",
       " 'biting': 509,\n",
       " 'cigarette': 510,\n",
       " 'parade': 511,\n",
       " 'restaurant': 512,\n",
       " 'skis': 513,\n",
       " 'setting': 514,\n",
       " 'fight': 515,\n",
       " 'parking': 516,\n",
       " 'inflatable': 517,\n",
       " 'paper': 518,\n",
       " 'cart': 519,\n",
       " 'tent': 520,\n",
       " 'sweatshirt': 521,\n",
       " 'skating': 522,\n",
       " 'faces': 523,\n",
       " 'hiking': 524,\n",
       " 'ears': 525,\n",
       " 'airborne': 526,\n",
       " 'family': 527,\n",
       " 'driving': 528,\n",
       " 'bus': 529,\n",
       " 'scarf': 530,\n",
       " 'chairs': 531,\n",
       " 'hit': 532,\n",
       " 'kicking': 533,\n",
       " 'low': 534,\n",
       " 'goes': 535,\n",
       " 'ring': 536,\n",
       " 'goal': 537,\n",
       " 'german': 538,\n",
       " 'tunnel': 539,\n",
       " 'goggles': 540,\n",
       " 'kayak': 541,\n",
       " 'short': 542,\n",
       " 'using': 543,\n",
       " 'crowded': 544,\n",
       " 'shepherd': 545,\n",
       " 'kick': 546,\n",
       " 'wheel': 547,\n",
       " 'hugging': 548,\n",
       " 'fallen': 549,\n",
       " 'bald': 550,\n",
       " 'cars': 551,\n",
       " 'canoe': 552,\n",
       " 'blanket': 553,\n",
       " 'dance': 554,\n",
       " 'cyclist': 555,\n",
       " 'pictures': 556,\n",
       " 'six': 557,\n",
       " 'pile': 558,\n",
       " 'boots': 559,\n",
       " 'silver': 560,\n",
       " 'have': 561,\n",
       " 'pushing': 562,\n",
       " 'jackets': 563,\n",
       " 'throws': 564,\n",
       " 'glass': 565,\n",
       " 'gold': 566,\n",
       " 'drinks': 567,\n",
       " 'sunset': 568,\n",
       " 'splashes': 569,\n",
       " 'wood': 570,\n",
       " 'painted': 571,\n",
       " 'held': 572,\n",
       " 'bmx': 573,\n",
       " 'leather': 574,\n",
       " 'backyard': 575,\n",
       " 'skate': 576,\n",
       " 'kicks': 577,\n",
       " 'closeup': 578,\n",
       " 'smaller': 579,\n",
       " 'stuffed': 580,\n",
       " 'garden': 581,\n",
       " 'beard': 582,\n",
       " 'surface': 583,\n",
       " 'event': 584,\n",
       " 'bottle': 585,\n",
       " 'volleyball': 586,\n",
       " 'blowing': 587,\n",
       " 'microphone': 588,\n",
       " 'hangs': 589,\n",
       " 'smoking': 590,\n",
       " 'door': 591,\n",
       " 'teenage': 592,\n",
       " 'diving': 593,\n",
       " 'fluffy': 594,\n",
       " 'statue': 595,\n",
       " 'piece': 596,\n",
       " 'bicyclist': 597,\n",
       " 'shaking': 598,\n",
       " 'band': 599,\n",
       " 'sports': 600,\n",
       " 'bikini': 601,\n",
       " 'corner': 602,\n",
       " 'party': 603,\n",
       " 'rugby': 604,\n",
       " 'outfits': 605,\n",
       " 'few': 606,\n",
       " 'sunny': 607,\n",
       " 'scooter': 608,\n",
       " 'graffiti': 609,\n",
       " 'furry': 610,\n",
       " 'sticking': 611,\n",
       " 'balls': 612,\n",
       " 'net': 613,\n",
       " 'below': 614,\n",
       " 'underwater': 615,\n",
       " 'full': 616,\n",
       " 'bicycles': 617,\n",
       " 'buildings': 618,\n",
       " 'sleeping': 619,\n",
       " 'end': 620,\n",
       " 'prepares': 621,\n",
       " 'snowboarding': 622,\n",
       " 'paint': 623,\n",
       " 'suits': 624,\n",
       " 'hind': 625,\n",
       " 'gathered': 626,\n",
       " 'bunch': 627,\n",
       " 'racetrack': 628,\n",
       " 'staring': 629,\n",
       " 'leg': 630,\n",
       " 'attempts': 631,\n",
       " 'sticks': 632,\n",
       " 'same': 633,\n",
       " 'costumes': 634,\n",
       " 'lays': 635,\n",
       " 'wrestle': 636,\n",
       " 'wrestling': 637,\n",
       " 'crossing': 638,\n",
       " 'phone': 639,\n",
       " 'log': 640,\n",
       " 'bride': 641,\n",
       " 'poles': 642,\n",
       " 'motorcyclist': 643,\n",
       " 'cup': 644,\n",
       " 'cat': 645,\n",
       " 'steep': 646,\n",
       " 'go': 647,\n",
       " 'dances': 648,\n",
       " 'do': 649,\n",
       " 'attached': 650,\n",
       " 'show': 651,\n",
       " 'plaid': 652,\n",
       " 'spectators': 653,\n",
       " 'clear': 654,\n",
       " 'throw': 655,\n",
       " 'flower': 656,\n",
       " 'pointing': 657,\n",
       " 'display': 658,\n",
       " 'way': 659,\n",
       " 'desert': 660,\n",
       " 'shot': 661,\n",
       " 'wide': 662,\n",
       " 'sprinkler': 663,\n",
       " 'fast': 664,\n",
       " 'box': 665,\n",
       " 'make': 666,\n",
       " 'teams': 667,\n",
       " 'kitchen': 668,\n",
       " 'beer': 669,\n",
       " 'pavement': 670,\n",
       " 'greyhounds': 671,\n",
       " 'bearded': 672,\n",
       " 'racket': 673,\n",
       " 'talks': 674,\n",
       " 'just': 675,\n",
       " 'swimsuit': 676,\n",
       " 'branch': 677,\n",
       " 'kissing': 678,\n",
       " 'tube': 679,\n",
       " 'beige': 680,\n",
       " 'stage': 681,\n",
       " 'gym': 682,\n",
       " 'mohawk': 683,\n",
       " 'attempting': 684,\n",
       " 'leans': 685,\n",
       " 'competition': 686,\n",
       " 'which': 687,\n",
       " 'wear': 688,\n",
       " 'skateboards': 689,\n",
       " 'bull': 690,\n",
       " 'shop': 691,\n",
       " 'police': 692,\n",
       " 'santa': 693,\n",
       " 'points': 694,\n",
       " 'facing': 695,\n",
       " 'hoop': 696,\n",
       " 'rain': 697,\n",
       " 'waving': 698,\n",
       " 'seat': 699,\n",
       " 'toys': 700,\n",
       " 'heads': 701,\n",
       " 'teeth': 702,\n",
       " 'paved': 703,\n",
       " 'racer': 704,\n",
       " 'pushes': 705,\n",
       " 'cowboy': 706,\n",
       " 'sheep': 707,\n",
       " 'hits': 708,\n",
       " 'headphones': 709,\n",
       " 'traffic': 710,\n",
       " 'fish': 711,\n",
       " 'carpet': 712,\n",
       " 'cow': 713,\n",
       " 'fenced': 714,\n",
       " 'drives': 715,\n",
       " 'hole': 716,\n",
       " 'chewing': 717,\n",
       " 'barefoot': 718,\n",
       " 'bucket': 719,\n",
       " 'platform': 720,\n",
       " 'hose': 721,\n",
       " 'cream': 722,\n",
       " 'headband': 723,\n",
       " 'ladies': 724,\n",
       " 'gravel': 725,\n",
       " 'birds': 726,\n",
       " 'dirty': 727,\n",
       " 'snow-covered': 728,\n",
       " 'unicycle': 729,\n",
       " 'shoulder': 730,\n",
       " 'wedding': 731,\n",
       " 'reads': 732,\n",
       " 'bottom': 733,\n",
       " 'eats': 734,\n",
       " 'wading': 735,\n",
       " 'close': 736,\n",
       " 'rough': 737,\n",
       " 'puppies': 738,\n",
       " 'downhill': 739,\n",
       " 'onlookers': 740,\n",
       " 'rural': 741,\n",
       " 'cross': 742,\n",
       " 'motocross': 743,\n",
       " 'showing': 744,\n",
       " 'match': 745,\n",
       " 'splash': 746,\n",
       " 'waits': 747,\n",
       " 'public': 748,\n",
       " 'bubble': 749,\n",
       " 'balloon': 750,\n",
       " 'bars': 751,\n",
       " 'landscape': 752,\n",
       " 'among': 753,\n",
       " 'video': 754,\n",
       " 'wire': 755,\n",
       " 'retriever': 756,\n",
       " 'resting': 757,\n",
       " 'fall': 758,\n",
       " 'purse': 759,\n",
       " 'boats': 760,\n",
       " 'urban': 761,\n",
       " 'wait': 762,\n",
       " 'younger': 763,\n",
       " 'parked': 764,\n",
       " 'scene': 765,\n",
       " 'goalie': 766,\n",
       " 'can': 767,\n",
       " 'amusement': 768,\n",
       " 'bandanna': 769,\n",
       " 'rolling': 770,\n",
       " 'races': 771,\n",
       " 'seated': 772,\n",
       " 'neck': 773,\n",
       " 'wings': 774,\n",
       " 'digging': 775,\n",
       " 'painting': 776,\n",
       " 'helmets': 777,\n",
       " 'foot': 778,\n",
       " 'beautiful': 779,\n",
       " 'empty': 780,\n",
       " 'poodle': 781,\n",
       " 'where': 782,\n",
       " 'art': 783,\n",
       " 'ropes': 784,\n",
       " 'hula': 785,\n",
       " 'wrestler': 786,\n",
       " 'signs': 787,\n",
       " 'african': 788,\n",
       " 'school': 789,\n",
       " 'lights': 790,\n",
       " 'pulled': 791,\n",
       " 'curly': 792,\n",
       " 'lit': 793,\n",
       " 'grinding': 794,\n",
       " 'filled': 795,\n",
       " 'atv': 796,\n",
       " 'handstand': 797,\n",
       " 'cricket': 798,\n",
       " 'opposing': 799,\n",
       " 'softball': 800,\n",
       " 'rapids': 801,\n",
       " 'gloves': 802,\n",
       " 'hikers': 803,\n",
       " 'outstretched': 804,\n",
       " 'third': 805,\n",
       " 'creek': 806,\n",
       " 'mother': 807,\n",
       " 'having': 808,\n",
       " 'matching': 809,\n",
       " 'lap': 810,\n",
       " 'jeep': 811,\n",
       " 'carnival': 812,\n",
       " 'talk': 813,\n",
       " 'spray': 814,\n",
       " 'hay': 815,\n",
       " 'chase': 816,\n",
       " 'appears': 817,\n",
       " 'christmas': 818,\n",
       " 'photograph': 819,\n",
       " 'smoke': 820,\n",
       " 'paddling': 821,\n",
       " 'stadium': 822,\n",
       " 'indoor': 823,\n",
       " 'skates': 824,\n",
       " 'tackle': 825,\n",
       " 'try': 826,\n",
       " 'market': 827,\n",
       " 'base': 828,\n",
       " 'shooting': 829,\n",
       " 'deck': 830,\n",
       " 'thrown': 831,\n",
       " 'brightly': 832,\n",
       " 'plate': 833,\n",
       " 'runner': 834,\n",
       " 'giant': 835,\n",
       " 'licking': 836,\n",
       " 'giving': 837,\n",
       " 'mouths': 838,\n",
       " 'wheelchair': 839,\n",
       " 'floating': 840,\n",
       " 'raises': 841,\n",
       " 'backpacks': 842,\n",
       " 'animals': 843,\n",
       " 'reaching': 844,\n",
       " 'funny': 845,\n",
       " 'basket': 846,\n",
       " 'seen': 847,\n",
       " 'terrain': 848,\n",
       " 'gather': 849,\n",
       " 'different': 850,\n",
       " 'alongside': 851,\n",
       " 'atop': 852,\n",
       " 'paddle': 853,\n",
       " 'lies': 854,\n",
       " 'balancing': 855,\n",
       " 'singing': 856,\n",
       " 'hitting': 857,\n",
       " 'fly': 858,\n",
       " 'larger': 859,\n",
       " 'putting': 860,\n",
       " 'before': 861,\n",
       " 'spotted': 862,\n",
       " 'rollerblades': 863,\n",
       " 'moving': 864,\n",
       " 'plants': 865,\n",
       " 'bushes': 866,\n",
       " 'falls': 867,\n",
       " 'newspaper': 868,\n",
       " 'competing': 869,\n",
       " 'riders': 870,\n",
       " 'ear': 871,\n",
       " 'professional': 872,\n",
       " 'enjoys': 873,\n",
       " 'hot': 874,\n",
       " 'station': 875,\n",
       " 'round': 876,\n",
       " 'blows': 877,\n",
       " 'bikers': 878,\n",
       " 'playfully': 879,\n",
       " 'straw': 880,\n",
       " 'preparing': 881,\n",
       " 'music': 882,\n",
       " 'duck': 883,\n",
       " 'indoors': 884,\n",
       " 'handrail': 885,\n",
       " 'jumped': 886,\n",
       " 'step': 887,\n",
       " 'seven': 888,\n",
       " 'teenagers': 889,\n",
       " 'audience': 890,\n",
       " 'shakes': 891,\n",
       " 'splashed': 892,\n",
       " 'hooded': 893,\n",
       " 'backs': 894,\n",
       " 'hang': 895,\n",
       " 'camouflage': 896,\n",
       " 'safety': 897,\n",
       " 'muzzled': 898,\n",
       " 'shows': 899,\n",
       " 'surfs': 900,\n",
       " 'formation': 901,\n",
       " 'cone': 902,\n",
       " 'terrier': 903,\n",
       " 'writing': 904,\n",
       " 'climbers': 905,\n",
       " 'muzzle': 906,\n",
       " 'lined': 907,\n",
       " 'gives': 908,\n",
       " 'passing': 909,\n",
       " 'pull': 910,\n",
       " 'spinning': 911,\n",
       " 'alone': 912,\n",
       " 'landing': 913,\n",
       " 'friend': 914,\n",
       " 'row': 915,\n",
       " 'flight': 916,\n",
       " 'laugh': 917,\n",
       " 'doorway': 918,\n",
       " 'follows': 919,\n",
       " 'owner': 920,\n",
       " 'coats': 921,\n",
       " 'home': 922,\n",
       " 'shaggy': 923,\n",
       " 'hoodie': 924,\n",
       " 'pipe': 925,\n",
       " 'block': 926,\n",
       " 'cloth': 927,\n",
       " 'chain': 928,\n",
       " 'instruments': 929,\n",
       " 'barrier': 930,\n",
       " 'leap': 931,\n",
       " 'himself': 932,\n",
       " 'gun': 933,\n",
       " 'finger': 934,\n",
       " 'opposite': 935,\n",
       " 'motorbike': 936,\n",
       " 'tug': 937,\n",
       " 'sea': 938,\n",
       " 'break': 939,\n",
       " 'says': 940,\n",
       " 'violin': 941,\n",
       " 'covering': 942,\n",
       " 'naked': 943,\n",
       " 'laughs': 944,\n",
       " 'quickly': 945,\n",
       " 'referee': 946,\n",
       " 'overalls': 947,\n",
       " 'pigeons': 948,\n",
       " 'pulls': 949,\n",
       " 'puts': 950,\n",
       " 'trunk': 951,\n",
       " 'foreground': 952,\n",
       " 'shoulders': 953,\n",
       " 'these': 954,\n",
       " 'bite': 955,\n",
       " 'motorcycles': 956,\n",
       " 'fur': 957,\n",
       " 'roller': 958,\n",
       " 'mound': 959,\n",
       " 'construction': 960,\n",
       " 'fair': 961,\n",
       " 'stop': 962,\n",
       " 'denim': 963,\n",
       " 'peace': 964,\n",
       " 'collie': 965,\n",
       " 'fetch': 966,\n",
       " 'float': 967,\n",
       " 'caught': 968,\n",
       " 'barking': 969,\n",
       " 'computer': 970,\n",
       " 'martial': 971,\n",
       " 'bank': 972,\n",
       " 'wheelie': 973,\n",
       " 'gate': 974,\n",
       " ';': 975,\n",
       " 'skiers': 976,\n",
       " 'clown': 977,\n",
       " 'uses': 978,\n",
       " 'rubber': 979,\n",
       " 'cut': 980,\n",
       " 'tie': 981,\n",
       " 'range': 982,\n",
       " 'counter': 983,\n",
       " 'staircase': 984,\n",
       " 'wagon': 985,\n",
       " 'shadow': 986,\n",
       " 'kite': 987,\n",
       " 'ducks': 988,\n",
       " 'medium': 989,\n",
       " 'jean': 990,\n",
       " 'tires': 991,\n",
       " 'reaches': 992,\n",
       " 'parachute': 993,\n",
       " 'jerseys': 994,\n",
       " 'spots': 995,\n",
       " 'dead': 996,\n",
       " 'rollerblading': 997,\n",
       " 'skater': 998,\n",
       " 'pack': 999,\n",
       " 'crashing': 1000,\n",
       " ...}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training_capt=tokenizer.texts_to_sequences(caption_train_list1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training_captions = caption_process(training_capt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[2, 1, 16, 10, 8, 34, 257, 1, 15, 10, 5, 6, 44, 4, 3],\n",
       " [2, 16, 10, 258, 27, 10, 35, 44, 3],\n",
       " [2, 14, 33, 816, 140, 86, 129, 6, 141, 167, 4, 3],\n",
       " [2, 14, 33, 84, 144, 5, 6, 44, 4, 3],\n",
       " [2, 14, 33, 34, 35, 1, 534, 444, 263, 13, 26, 4, 3]]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_captions[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<start> A black dog is running after a white dog in the snow . <end>',\n",
       " '<start> Black dog chasing brown dog through snow <end>',\n",
       " '<start> Two dogs chase each other across the snowy ground . <end>',\n",
       " '<start> Two dogs play together in the snow . <end>',\n",
       " '<start> Two dogs running through a low lying body of water . <end>']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "caption_train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "samples_per_epoch = 0\n",
    "for ca in caption_train_data:\n",
    "    samples_per_epoch += len(ca.split())-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "383377"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples_per_epoch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_captions_train = [len(captions) for captions in caption_train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "total_num_captions_train = np.sum(num_captions_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "steps_per_epoch = int(total_num_captions_train / 1024)\n",
    "steps_per_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "words = [i.split() for i in caption_train_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "unique = []\n",
    "for i in words:\n",
    "    unique.extend(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique = list(set(unique))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8253\n"
     ]
    }
   ],
   "source": [
    "vocab_size = len(unique)\n",
    "print(len(unique))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_len = 0\n",
    "for c in caption_train_data:\n",
    "    c = c.split()\n",
    "    if len(c) > max_len:\n",
    "        max_len = len(c)\n",
    "max_len\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "word_token = tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open( \"word_token.txt\", \"wb\" ) as pickle_f:\n",
    "    pickle.dump(word_token, pickle_f )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "encoding_train = pickle.load(open('train_encoded_images.p', 'rb'))\n",
    "encoding_test = pickle.load(open('val_encoded_images.p', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def data_generator(batch_size = 1024 ):\n",
    "    \n",
    "    partial_caps = []\n",
    "    next_words   = []\n",
    "    images       = []\n",
    "    \n",
    "    df= pd.read_csv(\"./Flickr8k_text/flickr_8k_train_dataset.txt\", delimiter='\\t')\n",
    "    df = df.sample(frac=1)\n",
    "    iter = df.iterrows()\n",
    "    c = []\n",
    "    imgs = []\n",
    "    for i in range(df.shape[0]):\n",
    "        x = next(iter)\n",
    "        c.append(x[1][1])\n",
    "        imgs.append(x[1][0])\n",
    "        \n",
    "    count = 0\n",
    "    while True:\n",
    "        for j,text in enumerate(c):\n",
    "            current_image = encoding_train[imgs[j]]\n",
    "            for i in range(len(text.split())-1):\n",
    "                count+=1\n",
    "                text = text.lower()\n",
    "                partial = [word_token[txt] for txt in text.split()[:i+1]]\n",
    "                partial_caps.append(partial)\n",
    "                # Initializing with zeros to create a one-hot encoding matrix\n",
    "                # This is what we have to predict\n",
    "                # Hence initializing it with vocab_size length\n",
    "                n = np.zeros(vocab_size)\n",
    "                # Setting the next word to 1 in the one-hot encoded matrix\n",
    "                n[word_token[text.split()[i+1]]] = 1\n",
    "                next_words.append(n)\n",
    "                    \n",
    "                images.append(current_image)\n",
    "\n",
    "                if count>=batch_size:\n",
    "                    next_words = np.asarray(next_words)\n",
    "                    images = np.asarray(images)\n",
    "                    partial_caps = sequence.pad_sequences(partial_caps, maxlen=max_len, padding='post')\n",
    "                    yield [[images, partial_caps], next_words]\n",
    "                    partial_caps = []\n",
    "                    next_words = []\n",
    "                    images = []\n",
    "                    count = 0           \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "embedding_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "image_model = Sequential()\n",
    "image_model.add(Dense(embedding_size,input_shape=(4096,),activation='relu'))\n",
    "image_model.add(RepeatVector(max_len))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 128)               524416    \n",
      "_________________________________________________________________\n",
      "repeat_vector_1 (RepeatVecto (None, 40, 128)           0         \n",
      "=================================================================\n",
      "Total params: 524,416\n",
      "Trainable params: 524,416\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "image_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Since we are going to predict the next word using the previous words(length of previous words changes with every iteration over the caption), we have to set return_sequences = True."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/meghanshu/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:1247: calling reduce_sum (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n"
     ]
    }
   ],
   "source": [
    "language_model = Sequential()\n",
    "language_model.add(Embedding(vocab_size,embedding_size,input_length=max_len))\n",
    "language_model.add(LSTM(256,return_sequences=True))\n",
    "language_model.add(TimeDistributed(Dense(embedding_size)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 40, 128)           1056768   \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 40, 256)           394240    \n",
      "_________________________________________________________________\n",
      "time_distributed_1 (TimeDist (None, 40, 128)           32896     \n",
      "=================================================================\n",
      "Total params: 1,483,904\n",
      "Trainable params: 1,483,904\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "language_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/meghanshu/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:2: UserWarning: The `Merge` layer is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "merge_1 (Merge)              (None, 40, 256)           0         \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 512)               1050624   \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 8256)              4235328   \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 8256)              0         \n",
      "=================================================================\n",
      "Total params: 7,294,272\n",
      "Trainable params: 7,294,272\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Merge([image_model,language_model],mode='concat',concat_axis=-1))\n",
    "model.add(Bidirectional(LSTM(256,return_sequences=False)))\n",
    "model.add(Dense(vocab_size))\n",
    "model.add(Activation('softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/meghanshu/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:1349: calling reduce_mean (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='categorical_crossentropy',optimizer=RMSprop(),metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/meghanshu/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:3: UserWarning: The semantics of the Keras 2 argument `steps_per_epoch` is not the same as the Keras 1 argument `samples_per_epoch`. `steps_per_epoch` is the number of batches to draw from the generator at each epoch. Basically steps_per_epoch = samples_per_epoch/batch_size. Similarly `nb_val_samples`->`validation_steps` and `val_samples`->`steps` arguments have changed. Update your method calls accordingly.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/home/meghanshu/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:3: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(<generator..., verbose=1, steps_per_epoch=383377, epochs=1)`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      " 71761/383377 [====>.........................] - ETA: 16:17:17 - loss: 4.5824 - acc: 0.3099"
     ]
    }
   ],
   "source": [
    "model.fit_generator(data_generator(batch_size=128),\n",
    "                    samples_per_epoch=samples_per_epoch,\n",
    "                    nb_epoch=1,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.optimizer.lr = 1e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.fit_generator(data_generator(batch_size=128),\n",
    "                    samples_per_epoch=samples_per_epoch,\n",
    "                    nb_epoch=1,verbose=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
